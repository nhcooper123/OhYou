% Preamble
\documentclass[a4paper,12pt]{article}

\usepackage[osf]{mathpazo} % palatino
\usepackage{ms}            % load the template
\usepackage[round]{natbib} % author-year citations
\usepackage{graphicx}
\usepackage{parskip} 
\usepackage{enumerate} 
\usepackage{longtable}
\usepackage{pdflscape}
\usepackage{fullpage}
\usepackage{hyperref}
%\usepackage[nomarkers, nolists]{endfloat}  % To push floats to the end   
\pagenumbering{arabic}    

% Title page information

\title{A cautionary note on the use of Ornstein Uhlenbeck models in macroevolutionary studies}
\author{
  Natalie Cooper$^{1,2,*,\dag}$, Gavin H. Thomas$^{3,\dag}$, Chris Venditti$^{4}$\\ Andrew Meade$^{4}$ and Rob P. Freckleton$^{3}$\\
}
\date{}
\affiliation{\noindent{\footnotesize
  
  $^1$ School of Natural Sciences, Trinity College Dublin, Dublin 2, Ireland.\\ 
  $^2$ Trinity Centre for Biodiversity Research, Trinity College Dublin, Dublin 2, Ireland.\\
  $^3$ Department of Animal and Plant Sciences, University of Sheffield, Sheffield S10 2TN, UK.\\
  $^4$ School of Biological Sciences, University of Reading, Reading, Berkshire, RG6 6BX, UK.\\
  $^*$ Corresponding author: ncooper@tcd.ie; Zoology Building, Trinity College Dublin, Dublin 2, Ireland. 
       Fax: +353 1 677 8094; Tel: +353 1 896 1926.\\
  $^\dag$These authors contributed equally.
}}

\vfill

\runninghead{A cautionary note on Ornstein Uhlenbeck models}
\keywords{OU - comparative methods - phylogeny - stabilising selection - macroevolutionary models}

% End of preamble

\begin{document}
\modulolinenumbers[1]   % Line numbering on every line

\mstitlepage
\parindent = 1.5em
\addtolength{\parskip}{.3em}

\section{Abstract}
  Phylogenetic comparative methods are increasingly used to give new insights into the dynamics of trait evolution in deep time. 
  The foundation of these methods is a suite of models that attempt to capture evolutionary patterns by extending the Brownian constant variance model. 
  However, the properties of these models are often poorly understood which can lead to the misinterpretation of results.
  Here we focus on one of these models - the Ornstein Uhlenbeck (OU) model.
  We show that the OU model is frequently incorrectly favoured over simpler models when using Likelihood ratio tests, and that many studies fitting this model use datasets that are small and prone to Type I error.   
  We also show that very small amounts of error in datasets can have profound effects on the performance of OU models.
  Our results suggest that simulating fitted models and comparing with empirical results is critical when fitting OU and other extensions of the Brownian model. 
  We conclude by making recommendations for best practice in fitting OU models in phylogenetic comparative analyses, and for interpreting the parameters of the OU model. 

\newpage
\raggedright
\doublespacing
\setlength{\parindent}{1cm}

\section{Introduction}
\label{section:introduction} 

  Phylogenetic comparative methods are powerful tools for identifying patterns in the evolution of species traits, and for potentially inferring the evolutionary processes that underlie them \citep[e.g.,][]{freckleton2009seven,Nunn:2011aa,o2012evolutionary,pennell2013integrative}. 
  These approaches have been used, for example, to infer potential rates of species responses to climate change \citep{Quintero:2013aa}, test the role of ecological niche as a driver of morphological evolution \citep{pienaar2013macroevolution}, and test for constraints in adaptive radiations \citep{blackburn2013adaptive}. 

  The majority of PCMs use an explicit evolutionary model to characterize trait evolution (Freckleton et al. 2011). Most model-based methods for characterizing trait evolution are based on the Brownian constant variance model \citep[for exceptions see][]{price1997correlated,harvey2000comparative,freckleton2006detecting}. 
  The Brownian model, first applied in a phylogenetic context by \citet{cavalli1967} and to across-species data by \citet{felsenstein1973maximum}, is a simple model of trait evolution in which trait variance accrues as a linear function of time, and makes the prediction that traits of closely-related species are more similar than those of distantly-related ones. 
  The Brownian model has been modified in various ways to account for a suite of ecological and evolutionary processes \citep[e.g.,][]{grafen1989phylogenetic,hansen1997stabilizing,Pagel:1997aa,Pagel:1999aa}. 
  The majority of these involve a transformation of the tree and thereby fitting a model with one or more extra parameters. 
  These modified Brownian models tend to fit better and often have links to process-based interpretations. 

  One of the most commonly used Brownian-like models is the Ornstein Uhlenbeck (OU) model. 
  The OU model was introduced to population genetics by \cite{Lande:1976aa} to model stabilising selection in which the trait is drawn towards a fitness optimum on an adaptive landscape. 
  The process operating in comparative data is analogous to but distinct from stabilising selection. The phylogenetic OU model is a modification of the Brownian model with an additional parameter $\alpha$ that measures the strength of return towards a theoretical optimum \citep{hansen1997stabilizing} that is shared across a clade or subset of species.
  Although widely used, the properties of the OU model, and other direct extensions of the Brownian model, are poorly understood leading to the potential for inappropriate use and misinterpretation of results.

  In this paper we present an introduction to the OU model, its general properties and some issues with its use in ecology, evolution and palaeontology.
  We use simulations to demonstrate the inherent bias in estimating the core parameter of the OU model, $\alpha$ that describes the strength of pull towards a central value (typically referred to as the trait or selective optima). We discuss the intricacies of interpreting OU models biologically, and provide advice for appropriate use of OU models in phylogenetic comparative analyses. 
  We also show that very small amounts of intraspecific trait variation (including measurement error) can profoundly affect on the performance of models. 
  These findings will be applicable to other models of evolution, but we focus on the OU model because of its widespread use and because of the ambiguity in the link between pattern and process when interpreting estimates of the $\alpha$ parameter. 
  We are not the first to describe these problems \citep[e.g.,][]{ho2013asymptotic,ho2014intrinsic,boettiger2012your,hansen2012interpreting,ives2010phylogenetic}. 
  However widespread use of the model is clear evidence that many are unaware of the potential problems. We use a simulation approach to summarize the problems and to generate practical recommendations of how to deal with them. 

\section{Uses of the OU model}
  The popularity of the OU model has grown extensively in recent years (Fig. \ref{figure.literature}); over 2500 ecology, evolution and palaeontology papers containing the phrase ``Ornstein Uhlenbeck'' were published between 2012 and 2014 (Google Scholar search 15th March 2015; see Supporting Information).
  This may partly be because these models are now easy to implement apply via packages in R \citep[e.g. ouch, GEIGER and OUwie;][]{Butler:2004aa,Harmon:2008aa,beaulieu2012ouwie}. 
  Additionally, although the OU model is pattern-based, it has a number of attractive biological interpretations. 
  For example, fit to an OU model is used as evidence for processes such as phylogenetic niche conservatism, convergent evolution and stabilising selection \citep[e.g.,][]{Wiens:2010aa,christin2013anatomical,ingram2013surface}. 
  It is important to note however, that although the OU model is frequently described and interpreted as a model of ``'stabilising selection'', this is inaccurate and misleading. 
  As formulated by \citet{hansen1997stabilizing}, a trait has a primary optimum that is the mean of individual species optimum for that trait. 
  Under this formulation, $\alpha$ can be considered as the strength of the pull towards a central value \citep[the primary optimum;][]{hansen2012adaptive}. 
  However, this is not an estimate of stabilising selection in the population genetics sense. 

    \begin{figure}[!htbp]
      \centering
      \includegraphics[width=10cm, height=10cm, keepaspectratio=true]{Figures/OhYou_Figure1.pdf}
      \caption{The number of ecology, evolutionary biology and palaeontology papers published between 2005 and 2014 containing the phrase ``Ornstein Uhlenbeck'', as a proportion of the total number of ecology, evolutionary biology or palaeontology papers published that year. See Supporting Information for details.
      }
      \label{figure.literature}
\end{figure}
% Weird issue with endfloat means these need to have no white space

  The OU model is most commonly used to model the evolution of a single continuous character (Table \ref{table.uses}; Supporting Information). 
  Usually several models of evolution \citep[e.g., Brownian motion, OU, Early burst etc.;][]{Harmon:2010aa,cooper2010body,cardillo2015geographic,slater2015iterative} are fit to the same continuous character and model selection is then used to determine which model best fits the data.  
  OU models can be fit with one optimal trait value, or multiple different optima \citep{Butler:2004aa,beaulieu2012modeling}. 
  The latter represents evolution under multiple selective regimes, and may be more biologically realistic for many datasets. 
  OU models with various numbers of optima are often included in the pool of evolutionary models being compared \citep[e.g.,][]{christin2013anatomical}(Table \ref{table.uses})
  OU models are also commonly used to control for phylogeny in correlative analyses (Table \ref{table.uses}; Supporting Information).  
  Phylogenetic generalised least squares (PGLS) models incorporate information about the relationships among species into the error term of a generalised least squares model. 
  This error term generally consists of a variance-covariance matrix of the phylogeny, but various transformations are used (e.g., Pagel's $\lambda$; \citealp{Pagel:1997aa}) to improve the fit of the model to the data. 
  The $\alpha$ parameter from an OU model can also be used to transform the tree and the variance-covariance matrix.
  This is rarely interpreted as corresponding to any kind of process,
  ; instead it improves the fit of the PGLS models \citep[e.g.,][]{blankers2012ecological}. 
  It is not clear that it was originally intended that the OU model would be used in such a context.
  Finally, the OU model is also used to reconstruct ancestral states \citep{martins1999estimation} and to detect clade-wide convergent evolution \citep{ingram2013surface}. 

  The majority of papers use the OU model to model the evolution of a continuous character (Table \ref{table.uses}; Supporting Information) therefore, we focus on this use of the OU model in our simulations below. 
  The principles here also apply to a range of other macroevolutionary models that can be fit to continuous data and compared using model testing procedures (e.g., $\kappa$, $\lambda$, $\delta$, ACDC, Early Burst; \citealp{Pagel:1997aa,Pagel:1999aa,Blomberg:2003aa,Harmon:2008aa}).
  Note that we focus on OU models with a single optimum trait value because these are more commonly used (Table \ref{table.uses}; Supporting Information) and easier to simulate.  For discussions on the performance of multiple optima OU models we refer the reader to \citep{beaulieu2012ouwie}.

    \begin{table}[!htbp]
      \begin{center}
        \caption{The most common uses of Ornstein Uhlenbeck models in ecology, evolutionary biology and palaeontology papers published between 2005 and 2013. See Supporting information for details.}
        \bigskip  
          \begin{tabular}{p{8cm}lc}
            \hline
            Use of OU model & Optima & Number of papers\\
            \hline
            Ancestral state reconstruction & single & 8\\
            & multiple & 2\\
            Convergent evolution & single & 0\\
            & multiple & 2\\
            Model of evolution & single & 31\\
            & multiple & 27\\
            Phylogenetic generalised least squares & single & 35\\
            & multiple & 0\\
            Other & single & 5\\
            & multiple & 5\\
            Total & single &  79\\
            & multiple & 36\\
            \hline
            \label{table.uses}
          \end{tabular}
      \end{center}
\end{table}
% Weird issue with endfloat means these need to have no white space
    
\section{OU model outline}
  
  According to the Brownian model \citep{cavalli1967,felsenstein1973maximum}, a trait X evolves at random at a rate $\sigma$:

      \begin{equation}
        dX(t) = \sigma dW(t)
      \end{equation}
    
    \noindent
    where $W(t)$ is drawn at random from a normal distribution with mean $0$ and variance $\sigma^2$. 
    The model assumes that there is no overall drift in the direction of evolution (hence the expectation of $W(t)$ is zero) and that the rate of evolution is constant. 
    Because the direction of change in trait values at each step is random, Brownian motion is often described as a ``random walk''.
    The model assumes the correlation structure among trait values is proportional to the extent of shared ancestry for pairs of species. 
    This means that close relatives will be more similar in their trait values than more distant relatives. It also means that variance in the trait will increase (linearly) in proportion to time. 
    The model has two parameters, the Brownian rate parameter, $\sigma^2$ and the state of the root at time zero, $X(0)$. 

   The OU model \citep{hansen1997stabilizing,Butler:2004aa} is a random walk where trait values revert back towards some ``optimal'' value with an attraction strength proportional to the parameter $\alpha$. 
    The model has the following form:
  
      \begin{equation}
        dX(t) = - \alpha (X(t) - \mu) + \sigma dW(t)
      \end{equation}
    
    \noindent
    Note that this model has two parameters in addition to those of the Brownian model: $\alpha$ and $\mu$. 
    The parameter $\mu$ is a long-term mean, and it is assumed that species traits evolve around this value. 
    $\alpha$ is the strength of evolutionary force that returns traits back towards the long-term mean if they evolve away from it. 
    $\alpha$ is sometimes referred to as the ``rubber band'' parameter because of the way it pulls traits back towards $\mu$. For more details see the Appendix.
    
    When $\alpha$ is close to zero, evolution is approximately Brownian, then as $\alpha$ gets larger the non-Brownian behaviour of the model starts to become apparent. 
    Eventually, when $\alpha$ is really large, all imprint of history is lost and the trait evolution is essentially a rapid burst at the present.
    Note that $\alpha$ scales with tree height, so it needs to be interpreted relative to this. 
    Generally the simplest solution is to rescale tree heights to 1 \citep[e.g.,][simulations below]{ives2010phylogenetic}. 
    \citet{ives2010phylogenetic} suggest interpreting $log( \alpha)$ (after rescaling trees to a height of 1) rather than raw $\alpha$. They equate $-log( \alpha) = -4$ as a very low, almost Brownian value, and $-log( \alpha) = 4$ as a very high value. 
    Others \citep[e.g.][]{slater2015iterative,slater2013robust,hansen2012interpreting} prefer to use the ``phylogenetic half-life'': $t_\frac{1}{2}$ (see ``Recommendations for interpreting $\alpha$'' below).  
  
\section{Performance of the OU model}

  To explore some issues with the OU model in more detail, we ran a number of simulations designed to mirror the use of OU models in the literature.

  \subsection{Simulating phylogenies and data}
    We simulated phylogenies with 25, 50, 100, 150, 200, 500, or 1000 tips under pure birth, constant-rate Birth-Death (extinction fractions of 0.25, 0.5 and 0.75), or temporally varying speciation rate (speciation rate modeled as time from the root raised to the power 0.2, 0.5, 2 and 5) models. 
    We simulated 1000 phylogenies for each combination of tips and models resulting in 56,000 simulated phylogenies in total. 
    Trees were simulated using the R package TESS \citep{hohna2013fast}. 
    We then simulated the evolution of a single trait under a Brownian motion model on each phylogeny using the R package MOTMOT \citep{Thomas:2011aa}. 
    All our simulated trees and data are available on GitHub: \href{https://github.com/nhcooper123/OhYou}{github.com/nhcooper123/OhYou}.

  \subsection{Performance of $\alpha$ and Likelihood ratio tests}
    To determine whether $\alpha$ is biased, and whether Likelihood ratio tests are appropriate for use with the OU model, we estimated $\alpha$ for each of our simulated phylogenies and data, and compared the fit of a Brownian model to that of an OU model using a Likelihood ratio test with 1 degree of freedom with the \texttt{transformPhylo.ML} function in MOTMOT (\citealp{Thomas:2011aa}; \href{https://github.com/ghthomas/motmot}{github.com/ghthomas/motmot}). 
    This mirrors the common situation where researchers fit Brownian and OU models and then use Likelihood ratio tests to select the ``best'' model.
    We then estimated the rejection rate of the null (Brownian) model for each set of simulations. 
    This gives us a measure of Type I error rate for the OU model.

      \begin{table}[!htbp]
        \begin{center}
        \caption{Rejection rate and $\alpha$ estimates for data simulated under a constant rate Brownian model on a range of constant-rate birth death trees. Tree type refers to the extinction fraction for the birth-death trees. The rejection rate is the proportion of OU models favoured relative to a Brownian motion model.}
        \bigskip
        \input{Tables/OU_bd_noerror.tex}
        \label{tables:bd_noerror}
        \end{center}
\end{table} 
% Weird issue with endfloat means these need to have no white space

      \begin{table}[!htbp]
        \begin{center}
        \caption{Rejection rate and $\alpha$ estimates for data simulated under a constant rate Brownian model on trees simulated under time variable speciation rates. The rejection rate is the proportion of OU models favoured relative to a Brownian motion model.}
        \bigskip
        \input{Tables/OU_var_rate_noerror.tex}
        \label{tables:varrate_noerror}
        \end{center}
\end{table} 
% Weird issue with endfloat means these need to have no white space

    We find that Type I error rates are unacceptably high when tree size is small (Tables \ref{tables:bd_noerror} and \ref{tables:varrate_noerror}), i.e., the OU model is often favoured, even though the Brownian model was used to generate the data. 
    For some tree shapes, particularly where speciation rates accelerate towards the present, Type I error remains \textgreater 0.05 even for trees with 1000 tips (Table \ref{tables:varrate_noerror}). 
    Indeed, for such trees the confidence limits on parameter estimates are broad (Figure \ref{figure:ouprofiles})
    This shows that, in general, analyses based on small datasets are prone to biases that decrease only slowly as the size of the dataset increases. 
    Unfortunately, OU models are often fitted to phylogenies with fewer than 100 taxa (mean = 166.97 $\pm$ 43.86, median = 58; Figure \ref{figure:ntaxa}; see Supporting Information). 

    \begin{figure}[!htbp]
      \centering
      \includegraphics[width=6cm, height=12cm, keepaspectratio=true]{Figures/OhYou_Figure2.pdf}
      \caption{Examples of profile likelihoods for selected simulated datasets. In all cases the ``true'' value of $\alpha$ is 0.
      }
      \label{figure:ouprofiles}
\end{figure}
% Weird issue with endfloat means these need to have no white space

    \begin{figure}[!htbp]
      \centering
      \includegraphics[width=10cm, height=10cm, keepaspectratio=true]{Figures/OhYou_Figure3.pdf}
      \caption{The number of taxa in phylogenies used to fit OU models in ecology, evolutionary biology and palaeontology papers published between 2005 and 2014. Two studies with \textgreater 3000 taxa have been omitted for clarity. See Supporting Information for details.
      }
      \label{figure:ntaxa}
\end{figure} 
% Weird issue with endfloat means these need to have no white space

    We provide recommendations related to these findings below.

\section{Effects of measurement error on OU model performance}
  Measurement error can strongly affect the results of comparative analyses \citep{silvestro2015}, and appears to influence whether OU is the favoured model across a range of datasets \citep[see][]{pennell2015model}. 
  Therefore, we also investigated whether adding error to our simulated data influenced estimates of $\alpha$.
  
  We used the same procedure as above to simulate trait data under a Brownian motion model with known error. 
  Specifically, we simulated trees under a Yule model with 25, 50, 100, 150, 200, 500, or 1000 tips and added branch length of (i) 1\%, (ii) 5\% or (iii) 10\% of the tree height to the tips of the simulated trees. 
  We then simulated data under a Brownian model on each tree. 
  All our simulated trees and data are available on GitHub: \href{https://github.com/nhcooper123/OhYou}{github.com/nhcooper123/OhYou}.

  We compared the fit of a Brownian model to that of an OU model using Likelihood ratio tests as described above, using the original trees without the addition of extra branch length to the tip edges. 
  Our expectation is that the OU model should fit the data better than the Brownian model because the $\alpha$ parameter should account for much of the error. In this case, rejection of the Brownian model does not represent Type I error because it would be quite correct to reject the Brownian. However, the reason for the better fit would be entirely unrelated to any macroevolutionary process. 

    \begin{landscape}
      \begin{table}[!htbp]
        \begin{center}
        \caption{Rejection rate and $\alpha$ estimates for data simulated under a constant rate Brownian model with 0, 1, 5, or 10\% measurement error (m.e.). The rejection rate is the proportion of OU models favoured relative to a Brownian motion model.}
        \bigskip
        \input{Tables/OU_yule_error.tex}
        \label{tables:yule_error}
        \end{center}
\end{table} 
% Weird issue with endfloat means these need to have no white space
    \end{landscape}

  Table \ref{tables:yule_error} shows the proportion of data sets in which the OU model is favoured over the Brownian model for data simulated under Brownian motion with error. 
  The expectation is that the OU model should fit better because the branch length transformation partially captures the non-Brownian component (the error). There are two points worth noting. 
  First, the frequency with which the OU model is favoured increases with tree size. With as little as 5\% error, the OU model becomes extremely difficult to reject, even for trees with just 100 species. 
  This is important for the interpretation of the OU model; we cannot conclude anything about evolutionary process from a single optimum OU model unless error is adequately accounted for. 
  Second, for moderate amounts of error (5-10\%), estimates of $\alpha$ are consistently \textgreater 1. 
  Large values of $\alpha$ are similarly difficult to interpret because they are indicative that the signal of the past has been overwritten. 

  \subsection{Limitations of the OU model}
  Although it is possible to create and implement new models for comparative data that encompass a range of processes, we have to be aware that such models are statistically complex and may behave in unexpected ways. 
  Transformations of the variance-covariance matrix in the Brownian model \citep[e.g. $\lambda$;][]{Pagel:1997aa} are an attractive and computationally simple way to modify the basic model to include evolutionary processes. 
  But, as first pointed out by \citet{grafen1989phylogenetic}, the statistical consequences of these modifications can include biases and problems with interpretation. 
  The results of our simulations illustrate that such problems can occur under conditions that closely match the size and type of datasets that are commonly used (Figure \ref{figure:ntaxa}, Supporting Information Table S1).
  
  In the case of the OU model, there are several limitations worth highlighting:
\begin{enumerate}[(i)]
  \item \textbf{Type I error rates are high when sample size is low.} 
  The results of the simulations indicate that, in general, analyses based on small datasets are prone to biases that decrease only slowly as the size of the dataset increases.  
  \item \textbf{Likelihood ratio tests are untrustworthy.}
  All Likelihood ratio tests depend on asymptotic properties, so there is no guarantee that any parameter such as $\alpha$ will behave appropriately when tested. 
  In the case of $\alpha$ we would expect these to be approximate because $\alpha$ is bounded and has a non-linear effect on the expected variances. 
  Our simulations indicate that Likelihood ratio tests should not be relied upon for analyses with small sample sizes, and that for robust inference and testing, alternatives, such as simulation and MCMC, should be considered. 
  \item \textbf{Measurement error increases Type I error rates.} 
  Our results show that a simple Brownian process can be mistaken for an OU process when a small amount of error is added to the data. 
  The effects of measurement error become more severe with increasing tree size.
  These limitations mean that when evidence for the OU model is found, the results should be interpreted with caution, particularly where there is likely to be intraspecific variation or measurement error in the data.
\end{enumerate}

\section{Recommendations and potential solutions}

  We have highlighted several issues with the OU model above. These can be broadly divided into two classes: (i) fitting the model and (ii) interpreting model parameters. These issues can be at least partially addressed with additional or alternative analytical approaches. Below we make recommendations for best practice in fitting model and approaches to interpret model parameters. We highlight areas of future research that may be important in alleviating outstanding issues.
  
  \subsection{Recommendations for model fitting}
    \begin{enumerate}[(i)]
      \item \textbf{Simulate under the null model.}
      OU models should not be applied to small trees. 
      Our simulations indicate that trees with \textgreater 200 tips are necessary to obtain acceptable Type I error rates. 
      However, we are cautious about recommending a minimum tree size because the performance of the OU model may vary among datasets for reasons other than tree size. 
      We note also that large trees are particularly susceptible to issues arising from unaccounted measurement error in the data. 
      Instead, we suggest using simulations to assess the model fit. 
      Simulating data under the BM model will generate null distributions \citep[e.g.,][]{boettiger2012your} and allow straightforward assessment of model fit, for example by generating appropriate critical values for Likelihood ratio tests. 
      \citet{boettiger2012your} discuss this at length and other papers use similar approaches \citep[e.g.,][]{freckleton2002phylogenetic, martins1991phylogenetic}.
    
      \item \textbf{Consider Bayesian approaches.}
      An alternative but less explored approach is to use Bayesian methods. 
      Bayesian model fitting has not been widely available for OU model fitting until recently but is now possible in R packages including diversitree \citep{FitzJohn:2012aa} and GEIGER \citep[the Single Stationary Peak model in \texttt{fitContinuousMCMC};][]{Harmon:2008aa} and stand alone software including BayesTraits \citep{pagel2013bayestraits}.
	
	    We (AM and CV) repeated the Maximum Likelihood simulations in a Bayesian framework implemented in BayesTraits \citep{pagel2013bayestraits}. 
      We determined fit to an OU model using Bayes factors estimated from a stepping stone sampling procedure \citep{xie2010improving}. 
      The marginal likelihoods of the models were calculated using a stepping stone sampler in which fifty stones were drawn from a beta distribution with (alpha = 0.4 and beta = 1). 
      Each stone was sampled for 20000 iterations (with the first 5000 iterations discarded). 
      We treated Bayes factors \textgreater 2 as evidence favouring the OU model \citep{kass1995bayes}. 
      We ran the MCMC chains for $1x10^6$ iterations, disregarding the first $1x10^4$ as burn-in.
      Following burn-in the chains were sampled every 1000 to ensure independence of each consecutive sample. 
      Multiple independent chains were run for each analysis to ensure convergence was reached. 
      An important challenge for Bayesian approaches is selection of appropriate priors. We used three alternative sets of priors on $\alpha$: (i) an exponential distribution with mean = 1; (ii), an exponential distribution with mean = 10, and (iii) a uniform distribution bounded at 0 and 20. 
      For all analyses we used a uniform -100 to 100 prior for $\mu$ and uniform 0 to 100 prior for $\sigma^2$. 
      
      Table \ref{tables:bayesian} shows the results from the exponential prior with mean = 10. This is a broad, liberal prior, but our results are similar regardless of priors. %add links to this
      The Bayesian approach results in highly conservative rejection rates regardless for all tree shapes in the absence of measurement error. 
      While this is encouraging from the perspective of falsely rejecting the Brownian null model, it is also indicative of potentially low statistical power, although testing would be required to confirm this. 
      The Bayesian approach also appears to more readily handle low levels of measurement error (Table \ref{tables:bayesian_error}). 
      With 1\% measurement error the Bayesian approach retains acceptable rejection rates (\textless 0.05) for trees of up to 150 tips. 
      However, more error or larger trees result in the frequent rejection of the Brownian model. 
      As noted above, this is not an issue of Type I and it is entirely correct that the Brownian model is rejected. 
      In such cases emphasis should shift to how the $\alpha$ parameter is interpreted. 
      Bayesian analysis is a promising approach for OU model fitting. 
      However, further testing of the Bayesian approach to simulated data sets under a wide range of values of $\alpha$ is necessary to fully characterize performance. 
      See \citet{pennell2015model} for more details on using Bayesian methods in evolutionary models.
    \end{enumerate}

    \begin{table}[!htbp]
        \begin{center}
        \caption{Rejection rate and $\alpha$ estimates for data simulated under a constant rate Brownian model on a range of constant-rate birth death trees using Bayesian methods. Tree type refers to the extinction fraction for the birth-death trees. The value of $\alpha$ is the median across simulated data sets based on modal estimates from the posterior distribution. The rejection rate is the proportion of OU models favoured relative to a Brownian motion model based on Bayes factors \textgreater 2.} 
        \bigskip
        \input{Tables/OU_bd_noerror_BayesTraits.tex} 
        \label{tables:bayesian}
        \end{center}
\end{table} 
% Weird issue with endfloat means these need to have no white space

    \begin{landscape}
      \begin{table}[!htbp]
        \begin{center}
        \caption{Rejection rate and $\alpha$ estimates for data simulated under a constant rate Brownian model with 0, 1, 5, or 10\% measurement error (m.e.) using Bayesian methods. The value of $\alpha$ is the median across simulated data sets based on modal estimates from the posterior distribution. The rejection rate is the proportion of OU models favoured relative to a Brownian motion model.} %NC: Might need to modify legend
        \bigskip
        \input{Tables/OU_yule_error_BayesTraits.tex}
        \label{tables:bayesian_error}
        \end{center}
\end{table} 
% Weird issue with endfloat means these need to have no white space
    \end{landscape}

  \subsection{Recommendations for interpreting $\alpha$}    
    \begin{enumerate}[(i)]
    \item \textbf{Consider plausible alternative hypotheses.}
    Because the OU model was proposed with evolutionary process in mind, alternative and arguably more parsimonious explanations for favouring OU models and interpreting non-zero $\alpha$ are often overlooked. 
    The effects of measurement error in particular suggest that $\alpha$ must always be interpreted with caution. 
    Many issues of misinterpretation can be solved by carefully inspecting the $\alpha$ parameter when an OU model is favoured. 
    Often, when Likelihood ratio tests suggest the OU model should be favoured over the Brownian model, estimates of $\alpha$ are actually very small and biologically indistinguishable from Brownian (e.g., examples in \citealp{Harmon:2010aa}).
    In these circumstances, it is likely that measurement error, or similar, is being mopped up by the extra parameters in the OU model. 
    Thus this does not reflect any kind of OU process underlying the data. 
    The similarity between Brownian and OU models with small $\alpha$ is demonstrated in (Figure \ref{figure:ouhistory}). 
    At the other extreme, as values of $\alpha$ become larger, the effects of changing $\alpha$ on model predictions are increasingly small and large values of $\alpha$ are indistinguishable from white-noise. 
    
     \begin{figure}[!htbp]
      \centering
      \includegraphics[width=6cm, height=12cm, keepaspectratio=true]{Figures/OhYou_Figure4.pdf}
      \caption{Scaling of expected trait similarity with time since evolutionary divergence predicted by the Ornstein Uhlenbeck model. The covariance between species' traits values is scaled by the intra-specific trait variance (i.e. equal to correlation between species' traits). This is plotted against the relative time of shared history (time at which species branched from each other, divided by the total tree height: $\frac{t_{ij}}{T}$).
      }
      \label{figure:ouhistory}
\end{figure}
    
    A good strategy for data exploration would be to simulate data under Brownian and the favoured OU model to generate distributions of parameters under known values. 
    These can then be compared to results for your dataset \citep[see][for a related approach]{slater2013robust}. 
    This is important because we have shown that the shape of a phylogeny has consequences for parameter biases and hypothesis tests. 
    Any given tree will therefore generate unique parameter estimates. 
    Generating data under the favoured OU model will allow an assessment of whether it is possible to retrieve known values, or whether there is evidence of bias. 
    
	  \item \textbf{Calculate the phylogenetic half-life.}
    The $\alpha$ parameter ranges from zero to infinity, thus recognising ``small'' or ``large'' values may not be intuitive. 
    $\alpha$ can sometimes be interpreted more easily by using it to estimate the ``phylogenetic half-life'' ($t_\frac{1}{2}$) of a trait, i.e., the time it takes for a species entering a new niche to evolve halfway toward its new expected optimum \citep{hansen1997stabilizing}, as follows:

      \begin{equation}
        t_\frac{1}{2} = \frac{ln(2)}{\alpha}
        \label{equation:halflife}
      \end{equation}
    
    \noindent
    If $t_\frac{1}{2}$ is short relative to the branch lengths of the phylogeny, evolution towards the optimum trait value is fast, residual phylogenetic correlations are weak, and there is little influence of the past on trait values \citep{hansen1997stabilizing}.
    $t_\frac{1}{2}$ equal to the height of the phylogeny is a moderate value \citep{hansen2012interpreting}.
    We would not advise interpreting $t_\frac{1}{2}$ as literally being ``the time it takes for a species entering a new niche to evolve halfway toward its new expected optimum''.
    However, if $t_\frac{1}{2}$ is extremely large, it suggests that if an OU process is acting, it is extremely weak, thus should not be interpreted as evidence of any kind of process. 
    As a further note of caution, it is important to recognise that biases in the estimation of $\alpha$ would lead to similar biases in $t_\frac{1}{2}$.
  
    \item \textbf{If possible, include ancillary data.}
    If data on fossils are available then these could be incorporated into the analysis \citep{Slater:2012ab}, provided their placement is well known.
    This is implemented in GEIGER \citep{Harmon:2008aa}.
    A caution here is that the OU model for non-ultrametric trees has to be carefully parameterized because for non-ultrametric trees the co-variances depend on both the shared distances between species and the distance of a node to the nearest tip (see equation \ref{equation:OUcov} in the Appendix). 
    This creates potential problems in parameterization and in interpretation because the variance-covariance matrix is no longer tree-like \citep{slater2014correction}.
    Some current implementations of the OU model are based on transforming the tree directly, rather than transforming the variance co-variance matrix \citep[e.g., MOTMOT;][]{Thomas:2011aa}. 
    These implementations should not be used with fossil data.
   \end{enumerate}  
    
\section{Conclusions and outstanding issues}
  A recurring theme from our simulations is that interpretation of OU models is not straightforward. 
  More focus is needed on the interpretation of $\alpha$ rather than simply model fit. 
  Even when the OU model is favoured, $\alpha$ may be so small as to be indistinguishable from Brownian motion in any biological sense. 
  It would clearly be very useful to have estimates of measurement error for all species traits, however the inclusion of species-specific variances has to be done carefully \citep[e.g.,][]{grafen1989phylogenetic}.
  Several approaches for accounting for error have been proposed and warrant wider implementation for OU models and other models of trait evolution \citep[e.g.,][]{lynch1991methods,hansen2012interpreting,martins1997phylogenies,rohlfs2013modeling,ives2007within}, however it is outside our scope to explore these here.

  Indeed, the problems that we report are not limited to OU models. 
  Any model of trait evolution that attempts to account for non-Brownian components of trait variation is susceptible to being misled by measurement error. 
  The fundamental problem is that rejection of the Brownian model in favour of another model does not necessarily say anything about process. 
  This problem can be alleviated to some extent if model comparisons are set in a firm hypothesis testing framework in which alternative hypotheses make clear predictions of emerging patterns that can be unambiguously associated with particular models \citep[e.g.,][]{Cooper:2011aa}. 
  We should not use any statistical model without thinking carefully about the limits in terms of both data and interpretation. 

\section{Epilogue: Open and (vaguely) reproducible science}
  At the symposium that generated this special issue, one of us (NC) gave a talk on Open Science and reproducibility. 
  We have therefore tried to make this paper as open and reproducible as possible. 
  All simulated phylogenies, data, and R code are available on GitHub: \href{https://github.com/nhcooper123/OhYou}{github.com/nhcooper123/OhYou}. However, although our R code is provided, it is messy and difficult to use. 
  We also do not provide an automated way of reproducing the data collection for our literature review. 
  Nor do we use tools like Travis CI (\href{https://travis-ci.org}{travis-ci.org}), Docker (\href{www.docker.com}{www.docker.com}), or packrat \citep{Ushey:2015aa} etc. to increase the reproducibility of our analyses. 
  Additionally, we use BayesTraits to run our Bayesian analyses. 
  BayesTraits is free to download as a binary executable for various platforms but it is not Open Source. 
  This means that while BayesTraits analyses are reproducible the software has limitations with respect to long-term development of the code. 
  We included this epilogue to highlight that fully reproducible and Open Science is really hard, but we are trying to improve! 
  With a little effort most people should be able to produce something vaguely reproducible, and to provide their data and code, moving us all slightly closer to truly reproducible and Open Science.

\section{Acknowledgments}
  Thanks to Rich FitzJohn, Mark Pagel, Matt Pennell and Graham Slater for fruitful discussions about OU models, and three anonymous reviewers for helpful comments on a previous version of this paper. 
  NC was supported by The European Commission CORDIS Seventh Framework Program (FP7) Marie Curie CIG grant, proposal number: 321696. 
  GHT was supported by a Royal Society University Research Fellowship. 
  CV was supported by a Leverhulme Trust Research Project Grant RPG-2013-185. 
  AM was supported by BBSRC grant BB/K004344/1 and the computing time was funded by European Research Council Grant no. 268744, ``MotherTongue''.

% Bibliography
\bibliographystyle{biolinnsoc}
\bibliography{ohyou}

% Appendix
\section{Appendix}
  \label{section:models}
  \setcounter{equation}{0}

  According to the Brownian model, a trait X evolves at random at a rate $\sigma$:

    \begin{equation}
      dX(t) = \sigma dW(t)
      \label{equation:BMrate} 
    \end{equation}

  where $W(t)$ is a white noise function and is a random variate drawn from a normal distribution with mean $0$ and variance $\sigma^2$. 
  This model assumes that there is no overall drift in the direction of evolution (hence the expectation of $W(t)$ is zero) and that the rate of evolution is constant. 
  The model has two parameters, $\sigma$ and the state of the root at time zero, $X(0)$. 
  The Brownian model predicts after a time $T$ the variance in trait value $X_i$ for species $i$ is:

    \begin{equation}
      var(X_i) = \sigma^2 T
      \label{equation:BMvar} 
    \end{equation}

  and the covariance in traits for species $i$ and $j$ is:
  
    \begin{equation}
      cov(X_i,X_j) = \sigma^2 t_{ij}
      \label{equation:BMcov} 
    \end{equation}

  where $t_{ij}$ is the shared evolutionary pathway for species $i$ and $j$, i.e. the time at which they last shared a common ancestor. 
  Equations \ref{equation:BMvar} and \ref{equation:BMcov} encapsulate the simplicity of the Brownian model, namely it predicts that variances accrue as a linear function of time. 

  The Ornstein Uhlenbeck (OU) model describes a mean-reverting process and has the following form, adding an extra term to the Brownian model:

  \begin{equation}
    dX(t) = - \alpha (X(t) - \mu) + \sigma dW(t)
    \label{equation:OUrate} 
  \end{equation}

  The parameter $\mu$ is a long-term mean, and it is assumed that species evolve around this value. 
  $\sigma$ is the strength of evolutionary force that returns traits back towards the mean if they evolve away. 
  This model has two parameters in addition to those of the Brownian model, $\alpha$ and $\mu$.
  The OU model predicts that after a time $T$ for a species $i$, the variance in trait value $X_i$ is:

    \begin{equation}
      var(X_i) = \frac{\sigma^2}{2 \alpha} 1 - e^{-2 \alpha T}
      \label{equation:OUvar} 
    \end{equation}

  And for a pair of species i and j, the covariance in traits is:

    \begin{equation}
      cov(X_i, X_j) = \frac{\sigma^2}{2 \alpha} e^{-2 \alpha (T - t_{ij})} (1 - e^{-2\alpha t_{ij}})
      \label{equation:OUcov} 
    \end{equation}

  The variances and covariances predicted by equations \ref{equation:OUvar} and \ref{equation:OUcov} are more complex than those predicted by the Brownian model. 
  In the light of the results above, some properties of this model are worth highlighting:

  \begin{enumerate}[(i)]
    \item If $\alpha$ is small then evolution is approximately Brownian: If $\alpha$ is small then $1 - e^{-2\alpha T} \approx 2\alpha T$, i.e. traits accrue variance as if evolving according to a Brownian process.\\ 

    \item If species $i$ and $j$ diverged recently, evolution is approximately Brownian: if two species diverged recently, then $T - t_{ij} \approx 0$ and hence $cov(X_i, X_j) \approx 1 - e^{-2\alpha t_{ij}} \approx 2\alpha t_{ij}$. 
    Thus, recently diverged species provide little information relevant to estimating non-Brownian evolution according to an OU process.\\ 

    \item In the long-term, the imprint of history is weakened: if $T$ is large (i.e. evolution proceeds for a long time), equation \ref{equation:OUvar} predicts that the variance in $X_i$ tends to a constant, i.e. because the expected value of $X_i$ is $\mu$. 
    Similarly, in equation \ref{equation:OUrate}, the covariance between traits tends to a constant because $T$ becomes large relative to $t_{ij}$.
    Consequently for large groups the model implies that the imprint of history is weak.\\
  \end{enumerate}

\newpage
\section{Figure legends}

\noindent
\textbf{Figure 1}: The number of ecology, evolutionary biology and palaeontology papers published between 2005 and 2014 containing the phrase ``Ornstein Uhlenbeck'', as a proportion of the total number of ecology, evolutionary biology or palaeontology papers published that year. See Supporting Information for details.\\

\noindent
\textbf{Figure 2}: Examples of profile likelihoods for selected simulated datasets. In all cases the ``true'' value of $\alpha$ is 0.

\noindent
\textbf{Figure 3}: The number of taxa in phylogenies used to fit OU models in ecology, evolutionary biology and palaeontology papers published between 2005 and 2014. Two studies with \textgreater 3000 taxa have been omitted for clarity. See Supporting Information for details.

\noindent
\textbf{Figure 4}: Scaling of expected trait similarity with time since evolutionary divergence predicted by the Ornstein Uhlenbeck model. The covariance between species' traits values is scaled by the intra-specific trait variance (i.e. equal to correlation between species' traits). This is plotted against the relative time of shared history (time at which species branched from each other, divided by the total tree height: $\frac{t_{ij}}{T}$).
      

\newpage
\section{Tables}

\end{document}
