\documentclass[12pt]{letter}
\usepackage[a4paper,left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm]{geometry}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[osf]{mathpazo}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\signature{Natalie Cooper \\ Gavin Thomas \\ Chris Venditti \\ Andrew Meade \\ Rob Freckleton}
\address{Department of Life Sciences \\ Natural History Museum \\ Cromwell Road \\ London, SW7 5BD \\ nhcooper12@gmail.com}
\longindentation=0pt
\begin{document}

\begin{letter}{}
\opening{Dear Dr Goswami}

Please find enclosed our resubmission of our manuscript ``A cautionary note on the use of Ornstein Uhlenbeck models in macroevolutionary studies" (BJLS-4095). We include below details of how we have dealt with the reviewers' comments. The reviewers' comments are in blue and our response is in black.

\textcolor{blue}{\textbf{Referee: 1}\\
The authors discuss some potential pitfalls in model choice and subsequent interpretation regarding the widely used OU model for analysing a single continuous trait on a phylogenetic tree. Due to the heavy usage of this model (as evidenced by the authors own literature survey) this is clearly an important paper, and the authors provide a broad array of simulations, which span a sufficient number of scenarios to characterise some major biases of the typical likelihood based model-fitting approach. The authors' interpretation of the results is measured and sensible (neither overly doom laden nor free of potential solutions). They have also strived to make their study repeatable whilst acknowledging the challenges in doing so and the limitations of their chosen approach. I have no problem supporting the publication of this paper, although I have a few notes (below) on potential improvements. These overwhelmingly ask for additional clarity on specific points and so I see them as minor.}

We thank the reviewer for their positive comments. 

\textcolor{blue}{L22 - Except these are exclusively for continuous data. Maybe use "core" instead of foundation, or a caveat like "at least for continuous data".}

Changed to core.

\textcolor{blue}{L28 (and L199) - I'm not sure if Type 1 error is the correct term to use as this is (to my mind) a frequentists term. I realise that we are (in a sense) rejecting the null of Brownian motion (albeit falsely) and that the LRT gives us a p-value to do so. However, the notion isn't necessarily generalisable to, e.g., three or more models. Perhaps the authors could just state explicitly what they mean by Type I errors to avoid confusion.}

Fair point. We mentioned what we mean by Type I error slightly above this point, so have replaced it with "and thus more prone to this problem" rather than repeating it in the abstract. Later in the manuscript we have clarified what we mean by Type I error when we first mention it.

\textcolor{blue}{L89 - The year range given here and that in the figure/figure caption are different.}

Yes this is correct. We meant to show that there have been lots of papers just within the last few years, and the figure was to show how these have increased over a slightly longer time-frame. We have rephrased to make this distinction clearer.

\textcolor{blue}{L102 - This explanation seems a little incomplete. Why isn't it?}

In population genetics stabilising selection describes selection within a species towards a fitness optimum. This is quite a different process biologically to the branching evolution of trait along a phylogeny and among different species towards an optimum trait value. We have added some explanation here to hopefully make this clearer. The population vs. clade level difference is key.

\textcolor{blue}{L124 - This also seems incomplete. Maybe insert "merely"?}

Added merely.

\textcolor{blue}{L156 - I think it would be helpful to discuss mu a bit more. Questions I would like to see answered include: Presumably this is the trait "optimum"? What does it mean to have an optimum outside of the range of the tip values? What if mu is unrealistic, e.g., continuous measure is wingspan and mu is 1000km? If mu is large/far from the tip mean does that mean alpha can be small and the model still be a better fit? etc.}

Yes mu is the optimal value. We have clarified this in the text. 

mu can sometimes be wildly inaccurate, though this is generally in implementations where the root state is estimated too leading to strange values appearing optimal on the likelihood surface. This is generally fixed by not estimating the root state, and instead using mu as the root state or a root state that is distributed according to the stationary distribution of the OU process. My feeling is that this happens rarely (most implementations don't estimate the root state by default) and hopefully people would notice this and take any results with a large pinch of salt. We have added a brief statement to alert people to this fact. We have also added more details on how mu is related to the state at the root as requested by the second reviewer. We did not go into mu too much here as our focus was on alpha since this is the parameter people tend to interpret.

\textcolor{blue}{L167 - I'm not totally clear what is meant by tree height (I think I know, but would prefer it to be defined explicitly), nor how or why it scales with alpha.}

Tree height is, probably as you suspected, the maximum height from the root to the tips of the tree. We have added this to the text. Alpha will scale negatively with tree height because the longer/taller the tree is, the more time there is for a trait to evolve back towards the optimum thus alpha - the strength of the force pulling the trait back towards the optimum - can be smaller. We have also added this to the text.

\textcolor{blue}{L188 - Lol.}

:)

\textcolor{blue}{L219 - Why did the authors chose a Yule model here and a birth-death earlier? Does it mean one is ultrametric and the other not? (Maybe this relates to the fossil point below.)}

A Yule model was chosen because time constraints meant we couldn't test every single different kind of tree as we did for the earlier analyses. As noted above, all of the simulated trees were ultrametric, so this should not influence our results. 

\textcolor{blue}{L263 - This paragraph could do with some unpacking. What asymptotic properties? How is alpha bounded? etc.}

We have clarified what we mean by bounded (alpha must be 0 or greater) and reworded this section to make it clearer and also in response to reviewer 2 below.

\textcolor{blue}{L267 - Does this extend, then, to AIC(c)s? (As many people use AIC instead of the LRT and fit more than two models this could be important.)}

\textcolor{red}{Rob?}
% NC: Need to add something here still...

\textcolor{blue}{L283 - "in fitting model" missing "the"?.}

Added "the".

\textcolor{blue}{L299 - Citations should be in date order.}

Corrected.

\textcolor{blue}{L325 - Do you mean "regardless OF"?}

Corrected.

\textcolor{blue}{L330 - Potential pregnancy (missing period).}

Haha corrected.

\textcolor{blue}{L342 - "processES"?}

Corrected.

\textcolor{blue}{L367 - Although in practice are there not ways to set limits on the min-max value of alpha?}

Yes that's correct, for example in GEIGER the default max is alpha = 150. We have added this information to the text. 

\textcolor{blue}{L376 - Maybe clarify exactly why (I think I have an idea!).}

If t1/2 is very high then it suggests it will take twice that long to reach the optimal trait value for the species. Thus it suggests that selection for that optimum is extremely weak at best. For example if t1/2 is 100 million years, then it suggests that a species will take 100 million years to get halfway to the trait optimum. This is hardly suggestive of a strong selective pressure towards that optimum. We have added this example to help clarify this point in the text.

\textcolor{blue}{L382 - Could or should? (Conflict of interest: I am a palaeobiologist!) It seems like fossils could really help as by definition they have smaller values of T, and hence are closer to the root, and hence are better at constraining the root, and hence (potentially) help with model choice in general. (E.g., AFAIK you can only really favour a trend model if you have fossils in the tree.) In addition, when the authors simulate the birth-death models are they using non-ultrametric trees? Or just pruning extinct tips? If the latter then they aren't really testing whether fossils can help, but maybe this could be mentioned as a possible future simulation study.}

The reviewer is correct that we do not include fossil taxa in our simulations. We used birth-death trees as a means of assessing the impact of different tree shapes rather than explicitly testing the impact of fossil taxa. The issue of whether fossil taxa should or could be included is not straightforward. If fossil taxa can be reliably placed in the phylogeny then we anticipate that they will typically improve model accuracy, i.e. they should be included. On the other hand, if placement of fossil taxa is unreliable then they also have the potential to mislead analyses (see Sansom \& Wills 2012 for examples).

\textcolor{blue}{L385 - Maybe I'm missing something here, but to my mind a non-ultrametric tree is not special in terms of co-variance. Rather it is the variances that are unusual. I.e., the diagonal of the VCV will not just be the same number (same T) for all species. In other words if you modified a non-ultrametric tree to make it ultrametric by making all tips range through to the "present" you would only be modifying the diagonal.}

The key point here is not that the tree itself is special but rather how the OU model is fitted. For ultrametric trees it is possible to fit the OU model simply by adjusting the branch lengths in the tree directly. This is not possible for non-ultrametric trees. The problem is that related species can effectively become more similar to one another than to themselves - an inherently not tree-like pattern. This means that the OU model can only be computed using the variance-covariance matrix, and not with the tree itself. The important point from an end-user perspective is that some software is not suitable for fitting the OU model to non-ultrametric trees. We have clarified this in the text.

\textcolor{blue}{L414 - Epilogue is fine in terms of content, but language is very informal ("vaguely", "messy", "!"). Maybe this isn't an issue, but does read to me as a definite shift in tone from the rest of the paper.}

We have made this less informal in tone.

\textcolor{blue}{Figure 2 caption - I think this caption could do more to explain the plot. What is meant by "rooty"? What is meant by "tippy"? What does each line represent? What are the dashed lines? etc.}

We have added details to this Figure caption. Tippy trees are those with distributed disproportionately late in the clade history (i.e. nearer to the present). Rooty trees are those with branching events distributed disproportionately early in the clades history (nearer to the root). In all cases the "true" value of alpha is 0 (black dashed line). The red dashed line is ... % NC: Need to add this!

\textcolor{red}{Rob?}

\textcolor{blue}{Figure 3 - Would be nice to have more "breaks" in the histogram to help visualise how the data is really distributed. The binning seems too coarse at the moment.}

We have added more breaks to this figure.

\textcolor{blue}{\textbf{Referee: 2 (Graham Slater)}\\
In this article, Cooper and colleagues explore through simulations one of phylogenetic comparative biologists worst kept but most ignored secrets - that the OU model (or, more specifically the single stationary peak version of the OU model) has poor statistical performance. Using a large number of simulated phylogenies derived under different branching processes, they find that: 1) OU has an undesirably high Type I error rate using Likelihood Ratio Tests (LRT), particularly for small trees; 2) ML estimates of the OU $\alpha$ - parameter are erroneously biased towards large values for small trees, and; 3) when measurement error is not accounted for, large datasets, rather than small datasets become more biased towards erroneously favoring OU. The authors provide a suite of practical recommendations for users fitting OU models to comparative datasets and even demonstrate, rather nicely, that using Bayesian model comparison machinery can lead to lower false positive rates than are obtained through ML methods.}

\textcolor{blue}{Overall, this is a nice contribution that will make a useful reference piece for comparative biologists using PCMs. BJLS is an appropriate outlet - although not normally associated with these kinds of papers, many contributions use these kinds of methods and I'm sure this one will be much read and cited.}

We thank the reviewer for their positive comments.

\textcolor{blue}{However, while I understand the authors’ frustrations with the fitting and interpretations of single peak OU processes that are common in the literature, I think they miss an opportunity to really emphasize their concerns here and demonstrate to readers that it's easy to correct oneself when support for OU comes back in comparative analyses. Though the authors do note that a best fitting OU model could be nothing more than a noisy BM processes based on parameter estimates, a closer look at their simulation results reveals that this is also the case here. For example, on their simulated trees rescaled to unit height, the highest median alpha estimated for the BM datasets is 0.165 for the 25 tip Yule tree. This translates into a phylogenetic half life of 4.2 time units however, 4 times the age of the simulated clade, which no sane macroevolutionary biologist would interpret as being too different from Brownian motion at this time scale! Furthermore, the upper 95\% HPDs (Quantiles surely?) are, in many cases low enough to result in questionable acceptance of OU over BM for any of the simulations.}

\textcolor{blue}{I think the authors could do a better job of emphasizing the implications of OU model parameters on the expected outcomes of the process with respect to their own simulations, perhaps by adding a section after line 211 on page 9 that explores alpha estimates and their associated phylogenetic half-lives. If the aim here is to caution readers that a best-fitting OU process does not always translate to evolution about a constrained peak, then showing this with parameter estimates from the simulations would be a useful contribution. This kind of constructive comment would also help those readers who would view this only as a critique of OU models.}

We agree that a half-life approximately 4 times the height of the tree is no different from Brownian motion in any meaningful biological sense. This is exactly the point. It is not uncommon to see interpretations of models based only on model fit and not on the the model parameters hence our emphasis is on problems with model fitting. However, the point about parameter interpretation is equally important and we have added a new paragraph (lines XX-XX) % NC: ADD LINE NUMBERS
to discuss this explicitly. 

Also yes, HPDs = quantiles. We have changed this throughout.

\textcolor{blue}{As I thought about this, it also occurred to me that it would probably be useful to more completely lay out how the OU process works. I suspect (from my own dealings with authors during reviews) that many do not have an intuitive feel for how the model works still. Based on this, I'd suggest that the authors move their appendix to the main ms and integrate it with the OU model outline on lines 139-174. It may additionally be useful to illustrate the process, both as a diffusion process and as its effects on the phylogenetic variance covariance structure. These are suggestions only, but I suspect that providing a more complete background to the models would further aid naive readers / students who are to be the main beneficiaries of this paper.}

We moved the details of the model to the appendix for the same reasons that the reviewer mentions - that it was aimed at naive readers/students. There is evidence to suggest that rather than helping naive readers, too many equations actually impedes understanding and communication of concepts (see Fawcett and Higginson, 2012 PNAS; http://www.pnas.org/content/109/29/11735.short), thus we prefer to keep this as it is so as not to discourage people from reading further. However, note that this is an in-print appendix, rather than online appendix, so will appear associated with the paper.

\textcolor{blue}{\textbf{Minor comments}\\
\textbf{SSP vs single peak OU.}\\
I think it would be useful to clarify early on in the ms that the scenario being explored is specifically a single stationary peak model (a la Harmon et al. 2010), rather than a single optimum model. Although I would agree that most users of these methods are more familiar with applying the latter term, there is a small distinction. A single peak OU process may have the root state the same as or different from the long term optimum, whereas the SSP model has both the same. Furthermore, interpretation of these two models with α ≅ 0 is slightly different. For SSP, α ≅ 0 approximates BM, but for a single peak model where the peak differs from the root state, α ≅ 0 collapses to BM with a trend (e.g., see Hansen 1996, Benson et al. 2014). Because the long term mean is introduced as a parameter of the OU process in eq 2 (line 156), it is perhaps worth pointing out this distinction at some point thereafter. Of course, the case where the root state and long term mean are not equal cannot be fitted when fossil data / strong root or internal node priors are lacking and so is unavailable to most PCM users anyway. But still, for completeness I think this is worth pointing out.}

This is a good point and we have clarified this in the text under where we first introduce mu. 

\textcolor{blue}{line 114. Perhaps my own bugaboo, but I hate the term “to control for phylogeny”. Perhaps replace this with “to model phylogenetically structured residual error in evolutionary correlations”. Revell (2010) might also make a nice citation here.}

We have changed this and added the citation, though in brackets we have left the term "controlling for phylogeny"
 as while it's not technically correct, it's how many people refer to this procedure.

\textcolor{blue}{Line 172: at the risk of losing a citation (although i think you’ll retain me elsewhere) Slater and Pennell used a rate half-life in the context of the exponential decline in rate under the ACDC model, not a phylogenetic half-life for the exponential approach of a trait to its long term mean under the OU model.}

Sorry for the error, we have removed the citation (but yes it's in there later anyway!)

\textcolor{blue}{The stepping stone analyses and results are very interesting. In Baele et al. (2012), which introduced path sampling for Bayesian demographic model selection using the BEAST software, the authors showed via simulation that Path Sampling and Stepping Stones performed much better than harmonic mean estimators or other model choice metrics at selecting a time homogeneous model over exponential growth (and also at choosing weak exponential growth over constant population size models). There seems a nice parallel here and this suggests that these kinds of approaches should probably be better integrated into comparative methods.}

We agree that Stepping Stones is better than the Harmonic Mean to estimate the marginal likelihood. And we agree that stepping stone sampling should be the method of choice for Bayesian comparative analyses. We have added a brief mention that Baele et al 2012 show that using stepping stone sampling is preferable to using harmonic means.

\textcolor{blue}{Lines 263-269: it may be more useful to be explicit here that LRTs assume that the LR statistic is asymptotically chi-square distributed and that this is unlikely the case here (perhaps you could show this using the simulations?). Link this to lines 288-299 to show how to obtain a simulated distribution for the LRT.}

We have altered this paragraph to make it clearer, also in response to comments from reviewer 1. We have also now signposted that potential solutions are described below in the "Recommendations" section.

\textcolor{blue}{lines 404-407: This works the other way too; not incorporating measurement error could lead one to reject a “high phylogenetic signal” model like EB in favor of BM when EB is intact the true model.}

We have added a comment in the text to say that measurement error can also favour BM over the true model.

\textcolor{blue}{Figure 2 legend what are the black and red dashed lines?}

We have added details to this Figure caption. Tippy trees are those with distributed disproportionately late in the clade history (i.e. nearer to the present). Rooty trees are those with branching events distributed disproportionately early in the clades history (nearer to the root). In all cases the "true" value of alpha is 0 (black dashed line). The red dashed line is ... % NC: Need to add this!

\textcolor{red}{Rob?}

Let us know if you require any further information,

\closing{Yours sincerely,}

\end{letter}
\end{document}
